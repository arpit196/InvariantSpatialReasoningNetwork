# -*- coding: utf-8 -*-
"""run-mnist.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1bBes9bqZ1nHRxbumGH7O2INon5j4NC31
"""

from tensorflow.keras.utils import to_categorical
from tensorflow.keras.datasets import cifar10,cifar100

from ipynb.fs.full.SpatialReasoningModel import *

# example of loading the mnist dataset
from numpy import mean
from numpy import std
from sklearn import datasets
from sklearn.manifold import TSNE
from matplotlib import pyplot as plt
from sklearn.model_selection import KFold
from tensorflow.keras.datasets import mnist
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D
from tensorflow.keras.layers import MaxPooling2D, AveragePooling2D
from tensorflow.keras.layers import Dense
from tensorflow.keras.layers import Flatten, BatchNormalization
from tensorflow.keras.optimizers import SGD
import tensorflow as tf

from tensorflow.keras.utils import to_categorical
#from tensorflow.keras.datasets import cifar10,cifar100
from tensorflow.keras.preprocessing.image import ImageDataGenerator
import tensorflow as tf
import keras
import numpy as np
def conc(*inp1):
  return layers.Concatenate()(inp1)

#!pip install tensorflow_addons
import tensorflow_addons as tfa

def mpool(psize,strides=2):
  return MaxPooling2D(pool_size=psize,strides=strides,padding="SAME")

def apool(psize,strides=None):
  if(strides is None):
    return AveragePooling2D(pool_size=psize,padding="SAME")
  else:
    return AveragePooling2D(pool_size=psize,strides=strides,padding="SAME")

def ln():
  return layers.LayerNormalization()

def bn():
  return layers.BatchNormalization()

def dense(size,act='relu'):
  return Dense(size,activation=act)

from keras.callbacks import ModelCheckpoint
import tensorflow.keras.layers as layers
filepath = 'my_best_model.hdf5'

def bnconv(inp,units,kernel_size):
  return BatchNormalization()(Conv2D(units,kernel_size,activation='relu',kernel_regularizer=tf.keras.regularizers.L2(0.0005))(inp))

def dense(units,act='relu'):
  return layers.Dense(units,activation=act)

def edim(inp,axis=-1):
    return tf.expand_dims(inp,axis)

def conv(inp,units,kernel_size):
  return Conv2D(kernel_size,units,activation='relu',kernel_regularizer=tf.keras.regularizers.L2(0.0005))(inp)

def cutout(image,size):
  return tfa.image.cutout(image,mask_size=(size,size))

def LaplacianFilter(input_tensor):
  filter = tf.constant([[[0.0,-1.0,0.0],[-1.0,4.0,-1.0],[0.0,-1.0,0.0]]])   #The filters for derivatives Cx, Cy ,[[0.0,-1.0],[1.0,0.0]]
  filter = filter[:,:,:,tf.newaxis]
  filter = tf.transpose(filter,[1,2,0,3])
  print(filter.shape)
  tf.print(filter[:,:,1,1])
  out = tf.nn.conv2d(input_tensor,filters=filter,padding="SAME",strides=[1, 1, 1, 1])  #basic convolution operation in tensorflow, the derivative filters are applied with stride 3
  return out


def LocalCurvature(input_tensor,scale=1,edge=True):
  filter = tf.constant([[[-1.0,0.0],[0.0,0.0]],[[1.0,0.0],[1.0,-1.0]]])   #The filters for derivatives Cx, Cy ,[[0.0,-1.0],[1.0,0.0]]
  filter = tf.transpose(filter,[1,2,0])
  filter = filter[:,:,tf.newaxis] #Expanding according to number of input channels
  filter = tf.tile(filter,[1,1,input_tensor.shape[-1],1])
  filter2 = tf.constant([[[0.0,0.0],[0.0,0.0]],[[1.0,0.0],[0.0,1.0]]])   #The filters for derivatives Cx, Cy ,[[0.0,1.0],[0.0,0.0]]
  filter2 = tf.transpose(filter2,[1,2,0])

  filter2 = filter2[:,:,tf.newaxis]
  filter2 = tf.tile(filter2,[1,1,input_tensor.shape[-1],1])                                         #Expanding according to number of input channels
  filter3 = tf.constant([[[1.0,0.0],[0.0,0.0]],[[0.0,0.0],[1.0,0.0]]])   #The filters for derivatives Cx, Cy ,[[0.0,0.0],[1.0,0.0]
  filter3 = tf.transpose(filter3,[1,2,0])
  filter3 = filter3[:,:,tf.newaxis]
  filter3 = tf.tile(filter3,[1,1,input_tensor.shape[-1],1])
  out2 = tf.nn.conv2d(input_tensor, filters=filter2,padding="SAME",dilations=scale,strides=[1, 1, 1, 1])
  out3 = tf.nn.conv2d(input_tensor, filters=filter3,padding="SAME",dilations=scale,strides=[1, 1, 1, 1])
  out = tf.math.abs(tf.nn.conv2d(input_tensor,filters=filter,dilations=scale,padding="SAME",strides=[1, 1, 1, 1]))  #basic convolution operation in tensorflow, the derivative filters are applied with stride 3
  if edge:
    return tf.where(tf.abs(out2*out3)>0,out,0.0)
  else:
    return out

def LocalCurvature(input_tensor,scale=1,edge=True):
  filter = tf.constant([[[-1.0,0.0],[1.0,0.0]],[[0.0,0.0],[1.0,-1.0]],[[0.0,-1.0],[1.0,0.0]]])   #The filters for derivatives Cx, Cy
  filter = filter[:,:,tf.newaxis]                                         #Expanding according to number of input channels
  filter = tf.tile(filter,[1,1,1,1])
  filter2 = tf.constant([[[0.0,0.0],[1.0,0.0]],[[0.0,0.0],[0.0,1.0]],[[0.0,1.0],[0.0,0.0]]])   #The filters for derivatives Cx, Cy
  filter2 = filter2[:,:,tf.newaxis]                                         #Expanding according to number of input channels
  filter3 = tf.constant([[[1.0,0.0],[0.0,0.0]],[[0.0,0.0],[1.0,0.0]],[[0.0,0.0],[1.0,0.0]]])   #The filters for derivatives Cx, Cy
  filter3 = filter3[:,:,tf.newaxis]
  filter2 = tf.tile(filter2,[1,1,1,1])
  out2 = tf.nn.conv2d(input_tensor, filters=filter2,padding="SAME",dilations=scale,strides=[1, 1, 1, 1])
  out3 = tf.nn.conv2d(input_tensor, filters=filter3,padding="SAME",dilations=scale,strides=[1, 1, 1, 1])
  out = tf.math.abs(tf.nn.conv2d(input_tensor,filters=filter,dilations=scale,padding="SAME",strides=[1, 1, 1, 1]))  #basic convolution operation in tensorflow, the derivative filters are applied with stride 3
  if edge:
    return tf.where(tf.abs(out2*out3)>0,out,0.0)
  else:
    return out

import tensorflow_datasets as tfds
import numpy as np

def preprocess_imagecont(image, label,image_size=28):
  image = tf.convert_to_tensor(image)
  image = tf.image.resize(image, [image_size,image_size])
  image1 = tfa.image.gaussian_filter2d(image, (2,2),3)
  image = tf.cast(image, tf.float32)
  #image = image/255.0
  positionsx1 = tf.range(start=0, limit=image_size, delta=float(1),dtype=tf.float32)
  positionsy1 = tf.range(start=0, limit=image_size, delta=float(1),dtype=tf.float32)
  positionsx1 = tf.expand_dims(tf.tile(tf.expand_dims(positionsx1,0),[image_size,1]),-1)
  positionsy1 = tf.expand_dims(tf.tile(tf.transpose(tf.expand_dims(positionsy1,0)),[1,image_size]),-1)
  positions11 = tf.concat([positionsx1,positionsy1],-1); positions11 = tf.tile(positions11[tf.newaxis,:,:,:],[image.shape[0],1,1,1])
  u = tf.image.sobel_edges(image1)
  angle = tf.where(u[:,:,:,0,0]!=0,tf.atan2(u[:,:,:,0,1],u[:,:,:,0,0]),0)
  angle = angle[:,:,:,tf.newaxis]
  #u = tf.reshape(u,[-1,image_size,image_size,6])

  image = tf.concat([image,angle/3.14,positions11],-1)
  #image = tf.concat([u[tf.newaxis,:,:,:],angle,positions11[tf.newaxis,:]],-1)
  #image=tf.squeeze(image,0)
  return image, label

labeled_batch_size=75
num_epochs = 60
batch_size = 30  # Corresponds to 200 steps per epoch
width = 28
temperature = 1
learning_rate=0.0001
#lr_drop=20


import keras.backend as K

#select = tf.convert_to_tensor(select,dtype=tf.float32)

def train(model,path,epochs=100):
    checkpoint1 = ModelCheckpoint(filepath='./'+path,save_format=tf,monitor='val_loss',
                            save_weights_only=True,
                             verbose=1,
                             save_best_only=True,
                             mode='min')
    model.compile(optimizer=tf.keras.optimizers.SGD(0.1,momentum=0.9),
    loss='categorical_crossentropy',
    metrics='categorical_accuracy')
    model.fit(trainXA, trainY, epochs=epochs, batch_size=200, validation_data=(testXA, testY), callbacks=[checkpoint1, reduce_lr], verbose=1)

learning_rate = 0.1
lr_drop=15
def lr_scheduler(epoch):
        return learning_rate * (0.5 ** (epoch // lr_drop))

reduce_lr = keras.callbacks.LearningRateScheduler(lr_scheduler)

image_size=28

def load_dataset():
	# load dataset
  (trainX, trainY), (testX, testY) = mnist.load_data()
  trainX = trainX.reshape((trainX.shape[0], 28, 28, 1))
  testX = testX.reshape((testX.shape[0], 28, 28, 1))
  return trainX, trainY, testX, testY

def prep_pixels(train, test):
	# convert from integers to floats
  train_norm = train.astype('float32')
  test_norm = test.astype('float32')
	# normalize to range 0-1
  train_norm = train_norm / 255.0
  test_norm = test_norm / 255.0
  normalization = layers.Normalization()
  normalization.adapt(train_norm)
  #train_norm=normalization(train_norm)
  #test_norm=normalization(test_norm)
  return train_norm, test_norm

trainX, trainY, testX, testY = load_dataset()
	# prepare pixel data
trainX, testX = prep_pixels(trainX, testX)
trainXA,trainY = preprocess_imagecont(trainX,trainY)
testXA,testY = preprocess_imagecont(testX,testY)
#train_images_res = tf.image.resize(trainXA,[48,48],method='bilinear')
#test_images_res = tf.image.resize(testXA,[48,48],method='bilinear')

trainY = tf.keras.utils.to_categorical(trainY,num_classes=10)
testY = tf.keras.utils.to_categorical(testY,num_classes=10)

testXA.shape

import math

learning_rate = 0.0001
lr_drop=20
def lr_scheduler(epoch):
        return learning_rate * (0.5 ** (epoch // lr_drop))

reduce_lr = keras.callbacks.LearningRateScheduler(lr_scheduler)

checkpoint_gen = ModelCheckpoint(filepath='./'+'generative_cifar_2',save_format=tf,monitor='val_val_loss',
                            save_weights_only=True,
                             verbose=1,
                             save_best_only=True,
                             mode='max')

def train(model,path,epochs=80):
  checkpoint1 = ModelCheckpoint(filepath='./'+path,save_format=tf,monitor='val_categorical_accuracy',
                            save_weights_only=True,
                             verbose=1,
                             save_best_only=True,
                             mode='max')
  model.compile(optimizer=tf.keras.optimizers.Adam(0.0001),
    loss='categorical_crossentropy',
    metrics='categorical_accuracy')
  model.fit(trainXA,trainY, epochs=epochs, batch_size=30, validation_data=(testXA,testY), callbacks=[reduce_lr,checkpoint1], verbose=1)

import math

def edim(inp,axis=-1):
    return tf.expand_dims(inp,axis)

import math

def test_invariance(model):
  print('original accuracy')
  print(str(model.evaluate(testXA,testY,verbose=0)[1]*100)+'%')
  print('Accuracy on Images scaled by factor:')
  print('1.1')
  print(str(affine_scale(model,1.1)[1]*100)+'%')
  print('1.2')
  print(str(affine_scale(model,1.2)[1]*100)+'%')
  print('1.3')
  print(str(affine_scale(model,1.3)[1]*100)+'%')
  print('1.4')
  print(str(affine_scale(model,1.4)[1]*100)+'%')
  affine_scale(model,2.0)
  print('Accuracy on Images sheared by factor:')
  print('0.1')
  print(str(affine_shear(model,0.1)[1]*100)+'%')
  print('0.2')
  print(str(affine_shear(model,0.2)[1]*100)+'%')
  print('0.4')
  print(str(affine_shear(model,0.4)[1]*100)+'%')
  print('0.5')
  print(str(affine_shear(model,0.5)[1]*100)+'%')

def affine_rot(model,theta):
    tr = tfa.image.rotate(testXA,(theta/180)*math.pi)
    image2 = tr
    #print(model.evaluate(testXA,testY))
    #indices = tf.where(tf.argmax(model(test_images),-1)==tf.argmax(test_labels),-1)
    #print(model.evaluate(image2[indices],test_labels[indices]))
    print(model.evaluate(tr,testY,verbose=0))

def affine_scale(model,scale):
    tr =  tfa.image.transform(testXA,[scale,0.0,0.0,0.0,scale,0,0,0])
    image2=tr
    return model.evaluate(image2,testY,verbose=0)

def affine_shear(model,scale):
    total_acc=0
    n=0
    #predictions1 = model.predict(testXA)
    #image2 =np.array(image2)
    tr = tfa.image.transform(testXA,[1.0,scale,0,scale,1.0,0,0,0])#tfa.image.shear_x(testXA,scale,replace=0.0) #
    #print(model.evaluate(testXA,testY))
    return model.evaluate(tr,testY,verbose=0)

import argparse

if __name__ == "__main__":
  parser = argparse.ArgumentParser(description='Create a SRN Model')
  parser.add_argument('--conv', metavar='path', required=False, default=1, type=int,
                        help='Number of convolutional layers before SRN layer, if none specified set to 1')
  args = parser.parse_args()
  print(args.conv)
  if int(args.conv==2):
    srn,_ = SpatialRelationsModel2Lyr()
  else:
    srn,_ = SpatialRelationsModel()
  train(srn,'SRN_MNIST',epochs=1)
  srn.load_weights('SRN_MNIST')
  test_invariance(srn)